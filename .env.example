# This file serves as a template for the .env file.
# Copy this file to .env and fill in your actual values.
# Lines starting with # are comments.

# === General Project Configuration ===
# Path to the input data file (Excel or CSV).
# Relative to the `phone_validation_pipeline` directory.
INPUT_EXCEL_FILE_PATH="data_to_be_inputed.xlsx"

# Specifies a range of rows (1-based inclusive) or a number of rows to process from the input file.
# Examples:
#   "10-20": Process rows 10 through 20.
#   "20":    Process the first 20 rows.
#   "10-":   Process from row 10 to the end of the file.
#   "-20":   Process the first 20 rows (same as "20").
#   "":      Process all rows. (Default if not set or invalid format)
ROW_PROCESSING_RANGE=""

# Base directory for all output files (processed data, scraped content, LLM context).
# Relative to the `phone_validation_pipeline` directory. Will be created if it doesn't exist.
OUTPUT_BASE_DIR="output_data"

# Template for the main output Excel file name.
# {run_id} will be replaced with the actual run ID (timestamp).
OUTPUT_EXCEL_FILE_NAME_TEMPLATE="phone_validation_output_{run_id}.xlsx"

# === Data Handling Enhancements ===
# Number of consecutive empty rows to detect as end-of-data when ROW_PROCESSING_RANGE is open-ended (e.g., "10-").
# Set to 0 or a negative value to disable this feature and revert to reading to the physical end of the file.
# Default is 3 if not set.
CONSECUTIVE_EMPTY_ROWS_TO_STOP="3"
# --- Filename Configuration ---
# FILENAME_COMPANY_NAME_MAX_LEN=25
# Sets the maximum length for the sanitized company name part of the output filenames.
# To avoid path length errors (especially on Windows, max path ~260 chars),
# consider your project's root path length and the fixed output subdirectories.
# Example Calculation for Windows (target total path < 255):
#   Typical Project Root: C:\Users\YourUser\Projects\MyProject (e.g., 40 chars)
#   Pipeline Output Base: phone_validation_pipeline/ (e.g., 26 chars, if running from MyProject)
#   Configured output_base_dir: output_data/ (12 chars)
#   Timestamped Run Folder: 20240101_120000/ (16 chars)
#   Fixed Subfolders: scraped_content/cleaned_pages_text/ (30 chars)
#   URL Hash Part of Filename: __domainpart_hash_cleaned.txt (approx. 35 chars)
#   Separators (slashes): approx. 7 chars
#   --------------------------------------------------------------------
#   Total Fixed Length (approx): 40 + 26 + 12 + 16 + 30 + 35 + 7 = 166 chars
#   Remaining Budget for Company Name: 255 - 166 = 89 chars.
#   A FILENAME_COMPANY_NAME_MAX_LEN around 20-30 should be very safe if your root path is longer,
#   or up to 50-80 if your root path is short. Adjust based on your actual root path.


# === Logging Configuration ===
# Log level for the main log file (e.g., DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL="INFO"
# Log level for the console output (e.g., DEBUG, INFO, WARNING, ERROR)
CONSOLE_LOG_LEVEL="WARNING"

# === LLM Configuration (Google Gemini) ===
# Your API key for the Google Gemini service. REQUIRED for LLM extraction.
GEMINI_API_KEY="YOUR_GEMINI_API_KEY_HERE"

# The specific Google Gemini model to use.
# Examples: "gemini-1.5-pro-latest", "gemini-1.5-flash-latest"
LLM_MODEL_NAME="gemini-1.5-pro-latest"

# Controls the randomness of the LLM's output. Range: 0.0 to 1.0.
# Lower values (e.g., 0.2) make output more deterministic.
# Higher values (e.g., 0.8) make output more random.
LLM_TEMPERATURE="0.5"

# Maximum number of tokens the LLM can generate in its response.
LLM_MAX_TOKENS="2048"

# Path to the text file containing the prompt template for the LLM.
# Relative to the `phone_validation_pipeline` directory.
LLM_PROMPT_TEMPLATE_PATH="prompts/gemini_phone_validation_v1.txt"

# Maximum number of retries if the LLM output number mismatches the input number.
# 0 means no retries. Default is 1.
LLM_MAX_RETRIES_ON_NUMBER_MISMATCH="1"

# === Web Scraper Configuration ===
# User-Agent string the scraper will use for HTTP requests.
SCRAPER_USER_AGENT="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"

# Default timeout for Playwright page operations in milliseconds (e.g., page.goto(), page.waitForSelector()).
SCRAPER_PAGE_TIMEOUT_MS="30000" # 30 seconds

# Default timeout for Playwright navigation actions in milliseconds.
SCRAPER_NAVIGATION_TIMEOUT_MS="60000" # 60 seconds

# Maximum number of retries for a failed scraping attempt on a URL.
SCRAPER_MAX_RETRIES="2"

# Delay in seconds between scraping retries.
SCRAPER_RETRY_DELAY_SECONDS="5"

# Timeout in milliseconds for waiting for network idle state after page load.
# Set to 0 to disable waiting for network idle (proceeds after DOM content loaded).
SCRAPER_NETWORKIDLE_TIMEOUT_MS="5000"

# Comma-separated list of keywords (case-insensitive) used to identify relevant internal links to scrape.
# Example: "contact,about,support,impressum,kontakt,legal,privacy,terms"
TARGET_LINK_KEYWORDS="contact,about,support,impressum,kontakt,legal,privacy,terms"

# Maximum depth to follow internal links from the initial company URL.
# 0 = only the initial URL.
# 1 = initial URL + direct links from it (matching keywords).
MAX_DEPTH_INTERNAL_LINKS="1"

# Number of characters before and after a regex match to include in the context snippet for the LLM.
# SNIPPET_WINDOW_LINES="3" # DEPRECATED
SNIPPET_WINDOW_CHARS="300" # Default 300 characters (150 before, 150 after)



# --- Advanced Link Prioritization and Control (New) ---
# Keywords that identify top-priority pages (e.g., "Impressum", "Kontakt") if found as a standalone path segment.
SCRAPER_CRITICAL_PRIORITY_KEYWORDS="impressum,kontakt,contact,imprint"

# Keywords for high-priority pages (e.g., "Legal", "Privacy") if found as a standalone path segment.
SCRAPER_HIGH_PRIORITY_KEYWORDS="legal,privacy,terms,datenschutz,ueber-uns,about,about-us"

# Max path segments for a priority keyword (critical or high) to retain its highest score tier.
# Longer paths with these keywords might get a slightly lower score.
SCRAPER_MAX_KEYWORD_PATH_SEGMENTS="3"

# Comma-separated URL path patterns. Links containing these patterns will be hard-excluded.
# Example: "/media/,/blog/,/forum/,/videos/"
SCRAPER_EXCLUDE_LINK_PATH_PATTERNS="/media/,/blog/,/wp-content/,/video/,/hilfe-video/"

# Limits the total number of pages scraped from a single domain. Set to 0 for no limit.
SCRAPER_MAX_PAGES_PER_DOMAIN="20"

# A link must achieve at least this score to be added to the scraping queue.
SCRAPER_MIN_SCORE_TO_QUEUE="40"

# When SCRAPER_MAX_PAGES_PER_DOMAIN is reached, only links scoring at or above this threshold will be processed.
SCRAPER_SCORE_THRESHOLD_FOR_LIMIT_BYPASS="80"

# After SCRAPER_MAX_PAGES_PER_DOMAIN is met, this is the max number of *additional* pages
# that can be scraped if they meet/exceed SCRAPER_SCORE_THRESHOLD_FOR_LIMIT_BYPASS.
# Helps to get a few very high-priority pages without scraping too many if a site is large. Default: 5
SCRAPER_MAX_HIGH_PRIORITY_PAGES_AFTER_LIMIT="5"
# --- End Advanced Link Prioritization ---

# === URL Handling Configuration ===
# Comma-separated list of Top-Level Domains (TLDs) to try appending to domain-like inputs
# that appear to be missing a TLD. The pipeline will attempt to probe these in order.
# Example: "de,com,at,ch,org,net"
URL_PROBING_TLDS="de,com,at,ch"

# === Robots.txt Handling for Scraper ===
# Whether the scraper should respect the robots.txt file of websites. (True/False)
RESPECT_ROBOTS_TXT="True"

# The user-agent string to use when checking robots.txt.
# "*" means it applies to all user-agents.
ROBOTS_TXT_USER_AGENT="*"

# === Phone Number Normalization Configuration ===
# Comma-separated list of ISO 3166-1 alpha-2 country codes (e.g., US, GB, DE).
# These are used as hints for parsing phone numbers and for validation.
TARGET_COUNTRY_CODES="DE,CH,AT" # Germany, Switzerland, Austria

# A default ISO 3166-1 alpha-2 country code to use if a phone number cannot be
# parsed with a specific country context or if no country context is available.
# This helps in formatting numbers that don't have an international prefix.
DEFAULT_REGION_CODE="DE"